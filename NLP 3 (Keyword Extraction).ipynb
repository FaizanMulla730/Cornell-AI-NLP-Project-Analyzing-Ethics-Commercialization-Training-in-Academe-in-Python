{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "439032c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Description  \\\n",
      "3                                                NaN   \n",
      "4  Entertainment forms of political communication...   \n",
      "5  Introduction to the theory of computational co...   \n",
      "6  Punk Cultureâ€“comprised of music, fashion, lite...   \n",
      "\n",
      "                                  CleanedDescription  BusinessWords  \n",
      "3                                        EmptyString              0  \n",
      "4  entertainment form political communication pop...              7  \n",
      "5  introduction theory computational complexity b...             12  \n",
      "6  punk culture comprise music fashion literature...              8  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keybert import KeyBERT\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Initialize KeyBERT with a specific SentenceTransformer model\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "kw_model = KeyBERT(model=sentence_model)\n",
    "\n",
    "# Define candidate business-related keywords\n",
    "candidate_keywords = [\n",
    "    \"marketing\", \"finance\", \"investment\", \"startup\",\n",
    "    \"entrepreneurship\", \"management\", \"corporate\", \"economics\",\n",
    "    \"venture capital\", \"market analysis\", \"business development\",\n",
    "    \"commercialization\", \"innovation\", \"strategic planning\"\n",
    "]\n",
    "\n",
    "# Initialize BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to get word embedding using BERT\n",
    "def get_word_embedding(word, tokenizer, model):\n",
    "    inputs = tokenizer(word, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze()\n",
    "\n",
    "# Precompute embeddings for candidate keywords\n",
    "candidate_embeddings = [get_word_embedding(word, tokenizer, model) for word in candidate_keywords]\n",
    "\n",
    "# Function to calculate cosine similarity\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    return 1 - cosine(vec1, vec2)\n",
    "\n",
    "# Function to count business-related keywords in text using KeyBERT\n",
    "def count_business_keywords(text):\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    keywords = kw_model.extract_keywords(text, keyphrase_ngram_range=(1, 2), stop_words='english', top_n=50, diversity=0.4)\n",
    "    count = 0\n",
    "    for keyword, _ in keywords:\n",
    "        keyword_vec = get_word_embedding(keyword, tokenizer, model)\n",
    "        for business_word_vec in candidate_embeddings:\n",
    "            similarity = cosine_similarity(keyword_vec, business_word_vec)\n",
    "            if similarity >= 0.85:\n",
    "                count += 1\n",
    "                break  # Assuming each keyword is counted only once even if it matches multiple business keywords\n",
    "    return count\n",
    "\n",
    "# Define the file path of the updated CSV\n",
    "updated_file_path = r'C:\\Users\\Lenovo\\OneDrive-CornellUniversity\\Desktop\\Cornell Meng CS\\MEng Project 2\\updated_extracted_data.csv'\n",
    "\n",
    "# Read the updated CSV file\n",
    "data = pd.read_csv(updated_file_path)\n",
    "\n",
    "# Add the \"BusinessWords\" column\n",
    "data['BusinessWords'] = data['Description'].apply(count_business_keywords)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "output_file_path = r'C:\\Users\\Lenovo\\OneDrive-CornellUniversity\\Desktop\\Cornell Meng CS\\MEng Project 2\\final_extracted_data.csv'\n",
    "data.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Updated CSV saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24b60b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
